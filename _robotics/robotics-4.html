---
title: "Robocon 2013: Manual Robot"
excerpt: "<br/><img src='/images/robotics/robocon2013/manual1.JPG'>"
collection: robotics
tags:
  - Robocon-2013
  - manual-robot
  - semi-automatic-robot
---

<hr style="border-color: silver;">
<a href="#" ><button type="button" class="btn btn--info"><i class="fa fa-github"></i> GitHub Source</button></a>
Team Size: 3
<!--<large>Source:</large> -->
<!--<iframe src="https://ghbtns.com/github-btn.html?user=gurumulay&repo=big-data-class/tree/master/n-gram-analysis-of-gutenberg&type=star&count=false&size=large" frameborder="0" scrolling="0" width="160px" height="30px"></iframe>-->
<hr style="border-color: silver;">


[TODO]




<!--&lt;!&ndash;##############&ndash;&gt;-->
<!--<p>-->
    <!--<big>-->
    <!--<b>Introduction:</b>-->
    <!--</big>-->
<!--</p>-->


<!--<p>-->
    <!--An N-gram is a contiguous sequence of N items from a given sequence of text or speech [1]. Probabilistic modeling of-->
    <!--N-grams is useful for predicting the next item in a sequence in Markov models.-->
    <!--For sequences of words, n-grams comprising of 1 word are called as unigram (1-gram). For set of 2 words, it's called as-->
    <!--bigram (2-gram), for set of 3 words it's called as trigram (3-gram) and so on.-->

    <!--For example, consider following sentence:-->
<!--</p>-->

<!--&lt;!&ndash;<p style="font-family:Lucida Console;">This is a paragraph.</p>&ndash;&gt;-->

<!--<p>-->
<!--<code style="font-size: 105%;">Let's study Big Data</code>-->
<!--</p>-->

<!--&lt;!&ndash;<br style="margin-bottom:25px;"/>&ndash;&gt;-->

<!--<p>-->
    <!--The 1-grams for this sentence are <code>["Let's", "study", "Big", "Data"]</code>. The 2-grams are-->
    <!--<code>["__, Let's", "Let's, study", "study, Big", "Big, Data", "Data, __"]</code>.-->
    <!--Here, "__" represents the empty space before and after the sentence which helps to distinguish whether the word was-->
    <!--used in the beginning or the end of the sentence or whether word was paired with other words.-->
<!--</p>-->


<!--<p>-->
    <!--N-gram analysis finds applications in many areas such as sequence prediction, sequence completion (such as the one-->
    <!--in Gmail's August 2018 updated version), plagiarism detection, searching for similar documents, sentiment analysis-->
    <!--automatic authorship detection, and linguistic cultural trend analysis.-->

    <!--Not to mention that Google has already spent several thousands of hours doing research in this field given that it-->
    <!--helps them in many products such as Google search engine, Gmail, Google Docs, Google Assistant, Google Voice-->
    <!--transcription, and many more. They have created a great tool called <a href="https://books.google.com/ngrams/">-->
    <!--Google Ngram Viewer</a> which allows you to analyse words from English (as well as several more languages) for their-->
    <!--frequency of use over time, occurrences in specific corpus, etc. You could get more information about this tool-->
    <!--<a href="https://books.google.com/ngrams/info"> here on info their page.</a>-->

<!--</p>-->



<!--<p>-->
    <!--For this project, the goal was to create an N-gram profile of a corpus of modern English literature formed by-->
    <!--subsetting around 1GB of dataset that included more than 2500 books from Gutenberg project [2]. Major steps-->
    <!--involved: (1) Extracting all the unigrams and bigrams, (2) Computing the frequency of each unigram and bigram, and (3) Ranking-->
    <!--the unigrams and bigrams based on those frequencies. I used-->
    <!--<a href="https://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html">Hadoop's</a>-->
    <!--<a href="https://en.wikipedia.org/wiki/MapReduce">MapReduce</a>-->
    <!--<a href=""></a> framework to generate the ngram profiles.-->

<!--</p>-->

<!--&lt;!&ndash;##############&ndash;&gt;-->
<!--<hr>-->
<!--<p>-->
    <!--<big>-->
    <!--<b>Dataset:</b>-->
    <!--</big>-->
<!--</p>-->

<!--<p>-->
    <!--Dataset - that was provided to us during the class - was compiled from the set of EBook files available as a part-->
    <!--of Project Gutenberg. It was a small subset of size ~1gb consisting of lines from several books from the-->
    <!--Project Gutenberg. Each line looked as follows:-->

    <!--<br style="margin-bottom:15px;"/>-->
    <!--<code>AUTHOR<===>DATE<===>A SINGLE LINE FROM THE DATASET FILE</code>-->
    <!--<br style="margin-bottom:15px;"/>-->


    <!--A specific example would be:-->

    <!--<br style="margin-bottom:15px;"/>-->
    <!--<code>Arthur Conan Doyle<===>June 19, 2008<===>"Well, by his insufferable rudeness and impossible behavior."</code>-->
    <!--<br style="margin-bottom:15px;"/>-->

    <!--For this project we were instructed to work with author's last name from <code>AUTHOR</code> field (last author in-->
    <!--case of multiple authors) and only the year part of <code>DATE</code> field. We converted the words into lowercase-->
    <!--to make them case insensitive. All the gender and tense identifier are treated as a separate word. Meaning "he" and-->
    <!--"she" were treated separately. Words "have" and "has" were treated as two separate words.-->
<!--</p>-->



<!--&lt;!&ndash;##############&ndash;&gt;-->
<!--<hr>-->
<!--<p>-->
    <!--<big>-->
    <!--<b>Methodology:</b>-->
    <!--</big>-->
<!--</p>-->


<!--<p>-->
<!--The ngram profile analysis generates following:-->

<!--<ol type="1">-->

    <!--<li><strong>Profile 1-A:</strong> A list of unigrams sorted by unigrams in an alphabetical ascending order. Within the same unigram, the list-->
    <!--should be sorted by year in an ascending order.</li>-->

    <!--<li><strong>Profile 1-B:</strong> A list of unigrams sorted by unigrams in an alphabetical ascending order. Within the same unigram, the list-->
    <!--should be sorted by authorâ€™s last name in an ascending order.</li>-->

    <!--<li><strong>Profile 2-A:</strong> A list of bigrams sorted by bigrams in an alphabetical ascending order. Within the same bigram, the list-->
    <!--should be sorted by year in an ascending order.</li>-->

    <!--<li><strong>Profile 2-B:</strong> A list of bigrams sorted by bigrams in an alphabetical ascending order. Within the same bigram, the list-->
    <!--should be sorted by author's last name in an ascending order.</li>-->

<!--</ol>-->

<!--</p>-->


<!--&lt;!&ndash;##############&ndash;&gt;-->
<!--<hr>-->
<!--<p>-->
    <!--<big>-->
    <!--<b>Outputs:</b>-->
    <!--</big>-->
<!--</p>-->

<!--Here are some snippets from the outputs of map reduce program for four profiles mentioned above. If you are interested-->
<!--you could get the entire files from a cloud bucket as below:-->



<!--<br/>-->
<!--<a href="-->
<!--https://project-data-store-public.storage.googleapis.com/csu-proj-data/big-data-stuff/guten1A"> Profile-1A,-->
<!--</a>-->

<!--<a href="-->
<!--https://project-data-store-public.storage.googleapis.com/csu-proj-data/big-data-stuff/guten1B"> Profile-1B,-->
<!--</a>-->

<!--<a href="-->
<!--https://project-data-store-public.storage.googleapis.com/csu-proj-data/big-data-stuff/guten2A"> Profile-2A,-->
<!--</a> and-->

<!--<a href="-->
<!--https://project-data-store-public.storage.googleapis.com/csu-proj-data/big-data-stuff/guten2B"> Profile-2B.-->
<!--</a>-->

<!--And the <a href="">source</a> as well.-->



<!--&lt;!&ndash;<a href="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten1A.png"><img  alt="gutenberg ngram analysis using hadoop map-reduce" src="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten1A.png" style="float: left; width: 40%; margin-right: 1%; margin-bottom: 0.5em;"  ></a>&ndash;&gt;-->
<!--&lt;!&ndash;<a href="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten1B.png"><img  alt="gutenberg ngram analysis using hadoop map-reduce" src="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten1B.png" style="float: left; width: 40%; margin-right: 1%; margin-bottom: 0.5em;"  ></a>&ndash;&gt;-->


<!--&lt;!&ndash;<a href="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten2A.png"><img  alt="gutenberg ngram analysis using hadoop map-reduce" src="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten2A.png" style="float: left; width: 48%; margin-right: 1%; margin-bottom: 0.5em;"  ></a>&ndash;&gt;-->
<!--&lt;!&ndash;<a href="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten2B.png"><img  alt="gutenberg ngram analysis using hadoop map-reduce" src="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten2B.png" style="float: left; width: 48%; margin-right: 1%; margin-bottom: 0.5em;"  ></a>&ndash;&gt;-->

<!--&lt;!&ndash;<figcaption>Fig. 2: BigQuery Interface</figcaption>&ndash;&gt;-->




<!--<div style="text-align: center">-->
    <!--<a href="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten1A.png">-->
        <!--<img src="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten1A.png" alt="gutenberg ngram analysis using hadoop map-reduce" align="middle" hspace="50" height="350">-->
    <!--</a>-->

    <!--<a href="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten1B.png">-->
        <!--<img src="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten1B.png" alt="gutenberg ngram analysis using hadoop map-reduce" align="middle" hspace="50" height="350">-->
    <!--</a>-->
    <!--<br/>-->
    <!--<br/>-->
    <!--<figcaption>Fig. 1: Profile 1A and 1B sample outputs</figcaption>-->
<!--</div>-->
<!--<br/>-->


<!--<br style="margin-bottom:10px;"/>-->
<!--<div style="text-align: center">-->
    <!--<a href="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten2A.png">-->
        <!--<img src="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten2A.png" alt="gutenberg ngram analysis using hadoop map-reduce" align="middle" hspace="30" height="350">-->
    <!--</a>-->

    <!--<a href="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten2B.png">-->
        <!--<img src="https://raw.githubusercontent.com/GuruMulay/big-data-class/master/n-gram-analysis-of-gutenberg/guten2B.png" alt="gutenberg ngram analysis using hadoop map-reduce" align="middle" hspace="30" height="350">-->
    <!--</a>-->
    <!--<br/>-->
    <!--<br/>-->
    <!--<figcaption>Fig. 2: Profile 2A and 2B sample outputs</figcaption>-->
<!--</div>-->
<!--<br/>-->





<!--&lt;!&ndash;##############&ndash;&gt;-->
<!--<hr>-->
<!--<p>-->
    <!--<big>-->
    <!--<b>References:</b>-->
    <!--</big>-->
<!--</p>-->


<!--<ol type="1">-->
    <!--<li>https://en.wikipedia.org/wiki/N-gram</li>-->
    <!--<li>https://www.gutenberg.org</li>-->
<!--</ol>-->


<!--&lt;!&ndash;##############&ndash;&gt;-->
<!--<hr>-->
<!--<p>-->
    <!--<small>-->
    <!--<b>Note:</b>-->
    <!--Some of the content for this post is taken from course material of CS435 (CSU) written by Prof. Sangmi Lee Pallickara and GTAs.-->
    <!--</small>-->
<!--</p>-->
<!--<hr>-->